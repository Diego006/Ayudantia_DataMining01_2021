---
title: "Ayudantia 8: Clustering Probabilistico"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Ayudantia 8

Para esta ayudantia utilizaremos un dataset que contiene la calidad de diversos vinos que se evaluaron

## Importar Librerias
```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(cluster)
library(factoextra)
```

Para un primer intento tomaremos todas las variables del dataset, ver que cluster obtenemos y como se comportan los indicadores de cada modelo

## Cargar Datos

```{r}
setwd("D:/Users/Italo/Documents/Italo Felipe/UAI/Semestre 11/Ayudantia Mineria de Datos/material ayudantia/Ayudantia8")

wine <- read.csv("winequality-red.csv",sep = ",")
wine <- wine[colnames(wine) %in% c("citric.acid","density", "pH", "sulphates", "alcohol","quality")]
```

## Comprobar Datos NA y Cambiar Tipo Data

```{r}
wine %>% 
  summarise_all(funs(sum(is.na(.))))

str(wine)

class <- wine$quality
X <- wine[,1:5]
head(X)
```
## Escalar Data

```{r}
data_sca <- sapply(X, scale) %>% as_tibble()

clPairs(data_sca,class)
```

# DBSCAN
Primer metodo, clustering basado en densidad

```{r, warning = FALSE, message = FALSE}
library(dbscan)

model = dbscan(data_sca, eps = 0.5, minPts = 7)

model

```

El modelo genera 7 clusters, basado en los parametros que le entregamos a la funcion dbscan.

Veamos que pasa al ir modificando esos valores

# Plot

```{r}

ggplot(data_sca, aes(alcohol, pH, color = factor(model$cluster), size = alcohol)) + 
  geom_point(alpha = 0.3) 

```

Se puede ver que hay diversos puntos que no quedan asignados a ningun cluster dados los valores escogidos para la distancia minima. 

Otros algoritmos como el c-means permiten asignarle un cluster a todos los puntos

# Fuzzy C Means

```{r}
library(e1071)

modelo_c_means <- cmeans(data_sca, 6, m=1.5) 

modelo_c_means$membership %>% head()

```

El algoritmo cmeans asigna como cluster al que tenga mayor probabilidad

```{r}
#Plot
ggplot(data_sca, aes(alcohol, pH, color = factor(modelo_c_means$cluster), size = alcohol)) + 
  geom_point(alpha = 0.3) 

```

Para los modelos de clustering difuso podemos calcular el Coeficiente de partición difusa (FPC) 

```{r}
# FCP

matriz <- modelo_c_means$membership%*%t(modelo_c_means$membership) # producto matricial

(FPC <- sum(matriz*diag(nrow(matriz)))/nrow(matriz))
```

El valor del FPC es bajo, lo que significa que los grupos tienen alta variabilidad, y se puede confirmar en la figura ya que no se ven grupos definidos.

# GMM

GMM permiten obtener clusters difusos pero utilizando modelos probabilisticos

```{r}
library(mclust)

model_gmm = Mclust(data_sca)

model_gmm 
summary(model_gmm, parameters = TRUE)

```

El modelo genero  clusters los que se pueden visualizar igual que los ejemplos anteriores

```{r}
# Plot
ggplot(data_sca) + 
  aes(x=alcohol, y=pH, color=factor(model_gmm$classification), size=alcohol) + 
  geom_point(alpha=0.5)

```

```{r}
fviz_cluster(model_gmm, data_sca, stand = FALSE, frame = FALSE,geom = "point")
```

El modelo aplicó todas las formas posibles de la matriz de covarianzas, y permite visualizar como evoluciona el BIC a medida que aumentamos el numero de clusters. Esta visualizacion permite ver que la mayoria de los modelos deja de mejorar sobre  clusters

# BIC

```{r}
plot(model_gmm, what = "BIC")
```